"""
Database Migration Runner for LockBay Performance Optimizations
==============================================================

Executes SQL migration files to ensure indexes and optimizations are applied.
This addresses the architect's concern about index persistence and verifiability.
"""

import logging
import os
from pathlib import Path
from sqlalchemy import text
from database import SessionLocal, engine

logger = logging.getLogger(__name__)


class DatabaseMigrationRunner:
    """
    Runs database migrations from SQL files to ensure performance optimizations
    are properly applied and verifiable in the repository.
    """
    
    def __init__(self):
        self.migrations_dir = Path(__file__).parent / "migrations"
        self.executed_migrations = set()
    
    def run_migration_file(self, filename: str) -> bool:
        """Run a specific migration SQL file"""
        migration_path = self.migrations_dir / filename
        
        if not migration_path.exists():
            logger.error(f"Migration file not found: {migration_path}")
            return False
        
        try:
            with open(migration_path, 'r') as f:
                sql_content = f.read()
            
            logger.info(f"üîß Executing migration: {filename}")
            
            with SessionLocal() as session:
                # Split by semicolon and extract actual SQL statements (ignore comments)
                raw_statements = [stmt.strip() for stmt in sql_content.split(';') if stmt.strip()]
                
                # Filter out pure comment blocks and extract actual SQL statements
                sql_statements = []
                for raw_stmt in raw_statements:
                    # Remove comment lines and get actual SQL
                    lines = raw_stmt.split('\n')
                    sql_lines = [line for line in lines if line.strip() and not line.strip().startswith('--')]
                    if sql_lines:
                        clean_sql = '\n'.join(sql_lines).strip()
                        if clean_sql.upper().startswith(('CREATE INDEX', 'ANALYZE')):
                            sql_statements.append(clean_sql)
                
                executed_count = 0
                for i, statement in enumerate(sql_statements):
                    try:
                        session.execute(text(statement))
                        session.commit()
                        executed_count += 1
                        logger.debug(f"‚úÖ Executed: {statement[:60]}...")
                    except Exception as e:
                        session.rollback()  # Always rollback on any error to reset session state
                        if "already exists" in str(e).lower():
                            executed_count += 1  # Count as success - index exists
                            logger.debug(f"Index already exists: {statement[:50]}...")
                        else:
                            logger.error(f"Statement {i+1} failed: {e}")
                            return False
                
                logger.info(f"üìä Migration executed {executed_count}/{len(sql_statements)} statements successfully")
                
            self.executed_migrations.add(filename)
            logger.info(f"‚úÖ Migration completed: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Migration failed: {filename}, Error: {e}")
            return False
    
    def run_all_migrations(self) -> bool:
        """Run all available migration files"""
        if not self.migrations_dir.exists():
            logger.warning(f"Migrations directory not found: {self.migrations_dir}")
            return False
        
        migration_files = sorted([f for f in os.listdir(self.migrations_dir) if f.endswith('.sql')])
        
        if not migration_files:
            logger.info("No migration files found")
            return True
        
        logger.info(f"üöÄ Running {len(migration_files)} migration files...")
        
        success_count = 0
        for filename in migration_files:
            if self.run_migration_file(filename):
                success_count += 1
        
        logger.info(f"üìä Migration results: {success_count}/{len(migration_files)} successful")
        return success_count == len(migration_files)
    
    def verify_indexes_created(self) -> dict:
        """Verify that performance indexes were successfully created"""
        try:
            with SessionLocal() as session:
                # Check for our performance indexes  
                index_check_query = text("""
                    SELECT 
                        COUNT(*) as total_performance_indexes,
                        COUNT(CASE WHEN indexname LIKE 'ix_users_%' THEN 1 END) as user_indexes,
                        COUNT(CASE WHEN indexname LIKE 'ix_escrows_%' THEN 1 END) as escrow_indexes,
                        COUNT(CASE WHEN indexname LIKE 'ix_transactions_%' THEN 1 END) as transaction_indexes,
                        COUNT(CASE WHEN indexname LIKE 'ix_cashouts_%' THEN 1 END) as cashout_indexes,
                        COUNT(CASE WHEN indexname LIKE 'ix_audit_logs_%' THEN 1 END) as audit_indexes
                    FROM pg_indexes 
                    WHERE schemaname = 'public' 
                        AND indexname LIKE 'ix_%'
                        AND indexname NOT IN ('ix_escrows_auto_release', 'ix_escrows_delivery_deadline', 'ix_escrows_utid')
                """)
                
                result = session.execute(index_check_query).fetchone()
                
                if result is None:
                    return {
                        "verification_status": "failed",
                        "error": "Query returned no results"
                    }
                
                # Expect at least 60 performance indexes
                expected_minimum = 60
                success = result.total_performance_indexes >= expected_minimum
                
                return {
                    "total_performance_indexes": result.total_performance_indexes,
                    "user_indexes": result.user_indexes,
                    "escrow_indexes": result.escrow_indexes,
                    "transaction_indexes": result.transaction_indexes,
                    "cashout_indexes": result.cashout_indexes,
                    "audit_indexes": result.audit_indexes,
                    "expected_minimum": expected_minimum,
                    "verification_status": "success" if success else "failed",
                    "verification_details": f"{result.total_performance_indexes}/{expected_minimum} indexes found"
                }
                
        except Exception as e:
            logger.error(f"Index verification failed: {e}")
            return {"verification_status": "failed", "error": str(e)}
    
    def get_migration_status(self) -> dict:
        """Get comprehensive migration and optimization status"""
        index_status = self.verify_indexes_created()
        
        return {
            "migrations_executed": list(self.executed_migrations),
            "migrations_directory": str(self.migrations_dir),
            "index_verification": index_status,
            "optimization_status": "production_ready" if index_status.get("verification_status") == "success" else "needs_attention"
        }


# Global migration runner instance
migration_runner = DatabaseMigrationRunner()


def ensure_performance_optimizations() -> bool:
    """
    Ensure all performance optimizations are applied.
    This function can be called during application startup.
    """
    logger.info("üîß Ensuring database performance optimizations are applied...")
    
    # Run migrations
    migration_success = migration_runner.run_all_migrations()
    
    # Verify indexes
    verification_result = migration_runner.verify_indexes_created()
    
    if verification_result.get("verification_status") == "success":
        logger.info(f"‚úÖ Performance optimizations verified: {verification_result['total_performance_indexes']} indexes active")
        return True
    else:
        logger.warning(f"‚ö†Ô∏è Performance optimization verification incomplete: {verification_result}")
        return migration_success


if __name__ == "__main__":
    # Allow running migration directly
    logging.basicConfig(level=logging.INFO)
    success = ensure_performance_optimizations()
    status = migration_runner.get_migration_status()
    print(f"Migration Status: {status}")
    exit(0 if success else 1)