"""
Production Database Pool Manager
Optimized connection pooling for cloud databases with connection warming and monitoring
"""

import logging
import time
import asyncio
import os
import sys
from typing import Optional, Dict, Any
from contextlib import contextmanager
from sqlalchemy import create_engine, pool, event, text
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import QueuePool
from config import Config
import threading
from collections import deque
from datetime import datetime, timedelta
from utils.ssl_connection_monitor import record_ssl_error, record_ssl_recovery, record_ssl_retry

logger = logging.getLogger(__name__)

def _is_test_environment() -> bool:
    """Check if we're running in a test environment"""
    return bool(os.environ.get("PYTEST_CURRENT_TEST") or "pytest" in str(sys.argv))


class OptimizedDatabasePool:
    """High-performance database pool with connection warming and monitoring"""
    
    def __init__(self):
        # ARCHITECT FIX: Skip initialization entirely in test environment
        if _is_test_environment():
            logger.info("üß™ TEST MODE: Skipping OptimizedDatabasePool initialization")
            self.engine = None
            self.SessionFactory = None
            self._warmed_sessions = []
            self._session_lock = threading.Lock()
            self._connection_times = deque(maxlen=100)
            self._pool_stats = {
                'connections_created': 0,
                'connections_reused': 0,
                'slow_connections': 0,
                'last_warning': datetime.min
            }
            return
        
        self.database_url = Config.DATABASE_URL
        if not self.database_url:
            raise ValueError("DATABASE_URL environment variable is required")
        
        # Performance metrics
        self._connection_times = deque(maxlen=100)
        self._pool_stats = {
            'connections_created': 0,
            'connections_reused': 0,
            'slow_connections': 0,
            'last_warning': datetime.min
        }
        
        # Create optimized engine with aggressive pooling
        self.engine = self._create_optimized_engine()
        
        # Session factory with scoped sessions for better reuse
        self.SessionFactory = sessionmaker(
            bind=self.engine,
            autocommit=False,
            autoflush=False,
            expire_on_commit=False  # Prevent unnecessary refreshes
        )
        
        # Pre-warmed connection pool with onboarding priority support
        self._warmed_sessions = []
        self._onboarding_warmed_sessions = []  # ARCHITECT FIX: Dedicated pool for onboarding priority
        self._session_lock = threading.Lock()
        
        # Start connection warming
        self._warm_connections()
        
    def _create_optimized_engine(self):
        """Create engine with optimized pooling for cloud databases"""
        
        # WEBHOOK RESILIENCE: Determine connection configuration based on usage context
        webhook_context = getattr(self, '_webhook_context', False)
        
        # WEBHOOK HARDENING: Increased timeouts for webhook processing paths
        if webhook_context:
            pool_timeout = 30  # WEBHOOK: Increased from 10s to 30s for webhook processing
            connect_timeout = 45  # WEBHOOK: Increased from 15s to 45s for webhook processing
            application_name = "escrow_bot_webhook_hardened"
            logger.info("üîó DATABASE_POOL: Using hardened timeouts for webhook processing")
        else:
            pool_timeout = 10  # Standard timeout for non-webhook operations
            connect_timeout = 15  # Standard timeout for non-webhook operations
            application_name = "escrow_bot_ssl_stable"

        # Use QueuePool for better control over connections with SSL stability
        engine = create_engine(
            self.database_url,
            poolclass=QueuePool,
            pool_size=15,  # MEMORY OPTIMIZATION: Reduced from 30 to 15 - saves memory
            max_overflow=25,  # MEMORY OPTIMIZATION: Reduced from 50 to 25 - prevents memory bloat
            pool_timeout=pool_timeout,  # WEBHOOK HARDENING: Dynamic timeout based on context
            pool_recycle=1800,  # SSL FIX: Increased from 300 to 1800s (30 min) - reduce SSL handshake frequency
            pool_pre_ping=True,  # SSL FIX: Enable pre-ping to detect stale SSL connections
            pool_reset_on_return='rollback',  # SSL FIX: Ensure clean connection state
            echo=False,  # Never echo in production
            connect_args={
                "application_name": application_name,
                "connect_timeout": connect_timeout,  # WEBHOOK HARDENING: Dynamic timeout based on context
                # SSL Configuration - use driver-agnostic SSL setting
                "sslmode": "require",  # SSL mode for psycopg2 sync connections
                "sslcert": None,  # SSL FIX: Explicit SSL config
                "sslkey": None,
                "sslrootcert": None,
                "keepalives": 1,
                "keepalives_idle": 30,
                "keepalives_interval": 5,
                "keepalives_count": 3,
                "tcp_user_timeout": 30000,  # SSL FIX: 30s TCP timeout for better SSL stability
                # Connection pooling at driver level with SSL stability
                "options": "-c statement_timeout=30s -c idle_in_transaction_session_timeout=30s -c tcp_keepalives_idle=30"
            }
        )
        
        # Add connection lifecycle events for monitoring
        @event.listens_for(engine, "connect")
        def on_connect(dbapi_conn, connection_record):
            connection_record.info['connect_time'] = time.time()
            self._pool_stats['connections_created'] += 1
            
        @event.listens_for(engine, "checkout")
        def on_checkout(dbapi_conn, connection_record, connection_proxy):
            # Track connection reuse
            connect_time = connection_record.info.get('connect_time', 0)
            age = time.time() - connect_time if connect_time else 0
            
            if age > 1:  # Connection older than 1 second = reused
                self._pool_stats['connections_reused'] += 1
                
        return engine
    
    def _warm_connections(self, num_connections: int = 3):
        """Pre-establish connections to reduce cold start latency with SSL stability"""
        # ARCHITECT FIX: Skip warming in test environment
        if _is_test_environment():
            logger.info("üß™ TEST MODE: Skipping connection warming")
            return
            
        try:
            # SSL FIX: Enhanced connection warming with SSL retry logic
            logger.info(f"üî• Warming {num_connections} database connections with SSL stability...")
            start_time = time.time()
            
            # MEMORY LEAK FIX: Ensure old warmed sessions are properly closed first
            for old_session in self._warmed_sessions:
                try:
                    old_session.close()
                except Exception as e:
                    pass
            self._warmed_sessions.clear()
            
            for i in range(num_connections):
                session = None
                for attempt in range(3):  # SSL FIX: Retry up to 3 times for SSL stability
                    try:
                        session = self.SessionFactory()
                        # SSL FIX: Enhanced connection validation
                        result = session.execute(text("SELECT 1, pg_backend_pid() as pid, inet_server_addr() as server"))
                        row = result.fetchone()
                        logger.debug(f"SSL connection {i+1} established to PID {row.pid if row else 'unknown'}")
                        self._warmed_sessions.append(session)
                        break  # Success, exit retry loop
                    except Exception as e:
                        error_msg = str(e)
                        if "SSL connection has been closed unexpectedly" in error_msg and attempt < 2:
                            # SSL MONITORING: Record SSL retry
                            record_ssl_retry(f"database_pool_warmup_{i+1}", attempt + 1, error_msg)
                            logger.debug(f"üîå SSL connection retry {attempt + 1}/3 for connection {i+1}: {error_msg}")
                            if session:
                                try:
                                    session.close()
                                except Exception as e:
                                    pass
                            # SSL FIX: Brief delay before retry
                            time.sleep(0.5)
                            continue
                        else:
                            # SSL MONITORING: Record SSL error
                            if "SSL connection has been closed unexpectedly" in error_msg:
                                record_ssl_error(f"database_pool_warmup_{i+1}", error_msg, attempt + 1)
                            logger.warning(f"Failed to warm connection {i+1} after {attempt + 1} attempts: {e}")
                            if session:
                                try:
                                    session.close()
                                except Exception as e:
                                    pass
                            break
            
            warm_time = time.time() - start_time
            logger.info(f"‚úÖ Warmed {len(self._warmed_sessions)} connections in {warm_time:.2f}s with SSL stability")
            
        except Exception as e:
            logger.error(f"Connection warming failed: {e}")
            # SSL FIX: Dispose engine on SSL errors to force fresh connections
            if "SSL" in str(e):
                logger.warning("üîå SSL error during warming - disposing engine for fresh SSL connections")
                self.engine.dispose()
    
    def set_webhook_context(self, enabled: bool = True):
        """Enable webhook context for hardened timeouts"""
        self._webhook_context = enabled
        if enabled:
            logger.info("üîó DATABASE_POOL: Webhook context enabled - using hardened timeouts")
        else:
            logger.info("üîó DATABASE_POOL: Webhook context disabled - using standard timeouts")
    
    def set_onboarding_context(self, enabled: bool = True):
        """Enable optimized context for onboarding flows with pre-warmed connections"""
        self._onboarding_context = enabled
        if enabled:
            logger.info("üëã DATABASE_POOL: Onboarding context enabled - optimizing for user registration")
            # Pre-warm additional connections for onboarding burst traffic
            self._warm_onboarding_connections()
        else:
            logger.info("üëã DATABASE_POOL: Onboarding context disabled")
    
    def _warm_onboarding_connections(self):
        """Pre-warm connections specifically optimized for onboarding workflows"""
        # ARCHITECT FIX: Skip warming in test environment
        if _is_test_environment():
            logger.info("üß™ TEST MODE: Skipping onboarding connection warming")
            return
            
        try:
            logger.info("üëã ONBOARDING OPTIMIZATION: Pre-warming connections for user registration flows...")
            
            # Pre-warm 2 additional connections for onboarding burst traffic
            for i in range(2):
                session = None
                try:
                    session = self.SessionFactory()
                    # ARCHITECT FIX: Use lightweight existence checks instead of COUNT(*) to avoid full table scans
                    session.execute(text("""
                        BEGIN;
                        SELECT 1 FROM users LIMIT 1;
                        SELECT 1 FROM onboarding_sessions LIMIT 1;
                        SELECT 1, 'onboarding_ready' as status;
                        COMMIT;
                    """))
                    
                    # ARCHITECT FIX: Use session lock to prevent races and store in dedicated pool
                    with self._session_lock:
                        self._onboarding_warmed_sessions.append(session)
                    logger.debug(f"üëã Onboarding connection {i+1} warmed successfully (dedicated pool)")
                    
                except Exception as e:
                    logger.warning(f"Failed to warm onboarding connection {i+1}: {e}")
                    if session:
                        try:
                            session.close()
                        except Exception as e:
                            pass
            
            logger.info(f"üëã ONBOARDING OPTIMIZATION: Warmed {len(self._onboarding_warmed_sessions)} dedicated onboarding connections, {len(self._warmed_sessions)} general connections")
            
        except Exception as e:
            logger.error(f"Onboarding connection warming failed: {e}")
    
    def _warm_onboarding_connections_dedicated(self):
        """Warm a single dedicated onboarding connection (thread-safe)"""
        if _is_test_environment():
            return
            
        try:
            session = self.SessionFactory()
            # ARCHITECT FIX: Lightweight validation without full table scans
            session.execute(text("SELECT 1 FROM users LIMIT 1"))
            
            with self._session_lock:
                self._onboarding_warmed_sessions.append(session)
            
            logger.debug("üëã Warmed 1 dedicated onboarding connection")
            
        except Exception as e:
            logger.warning(f"Failed to warm dedicated onboarding connection: {e}")
            if 'session' in locals() and session:
                try:
                    session.close()
                except Exception as e:
                    pass

    @contextmanager
    def get_session(self, context_id: str = "default"):
        """Get a database session with SSL connection stability and retry logic
        
        Enhanced with onboarding-specific optimizations for faster user registration.
        """
        start_time = time.time()
        session = None
        retry_count = 0
        max_retries = 3
        
        # ONBOARDING OPTIMIZATION: Detect onboarding context for priority handling
        is_onboarding_context = (
            context_id.startswith('onboarding') or 
            'onboarding' in context_id.lower() or
            getattr(self, '_onboarding_context', False)
        )
        
        while retry_count < max_retries:
            try:
                # ONBOARDING OPTIMIZATION: True priority session allocation with dedicated pools
                with self._session_lock:
                    session = None
                    
                    # ARCHITECT FIX: Use dedicated onboarding pool for true priority
                    if is_onboarding_context and self._onboarding_warmed_sessions:
                        session = self._onboarding_warmed_sessions.pop()
                        logger.debug(f"üëã ONBOARDING PRIORITY: Using dedicated onboarding session for {context_id}")
                    elif self._warmed_sessions:
                        session = self._warmed_sessions.pop()
                        if is_onboarding_context:
                            logger.debug(f"üëã ONBOARDING FALLBACK: Using general pool session for {context_id}")
                    
                    if session:
                        
                        # SSL FIX: Validate session is still alive before using
                        try:
                            if is_onboarding_context:
                                # Onboarding-optimized validation with table readiness check
                                result = session.execute(text("SELECT 1, pg_backend_pid() as pid"))
                                logger.debug(f"üëã Using validated onboarding session for {context_id} (PID: {result.fetchone()[1]})")
                            else:
                                session.execute(text("SELECT 1"))
                                logger.debug(f"Using validated pre-warmed session for {context_id}")
                        except Exception as validation_error:
                            if "SSL connection has been closed" in str(validation_error):
                                logger.debug(f"üîå Stale SSL session detected for {context_id}, creating new one")
                                session.close()
                                session = None
                            else:
                                raise
                        
                # Create new session if no warmed ones available or validation failed
                if session is None:
                    if is_onboarding_context:
                        logger.debug(f"üëã ONBOARDING: Creating fresh optimized session for {context_id}")
                    session = self.SessionFactory()
                    
                # Track connection time
                connection_time = time.time() - start_time
                self._connection_times.append(connection_time)
                
                # ONBOARDING OPTIMIZATION: More aggressive monitoring for user registration flows
                slow_threshold = 1.5 if is_onboarding_context else 2.0  # Lower threshold for onboarding
                
                # Log slow connections (but rate-limit warnings)
                if connection_time > slow_threshold:
                    self._pool_stats['slow_connections'] += 1
                    now = datetime.now()
                    if now - self._pool_stats['last_warning'] > timedelta(seconds=30):
                        context_emoji = "üëã" if is_onboarding_context else "üîå"
                        context_type = "ONBOARDING" if is_onboarding_context else "SSL"
                        logger.warning(
                            f"‚ö†Ô∏è Slow {context_type} connection ({connection_time:.2f}s) for {context_id}. "
                            f"Stats: created={self._pool_stats['connections_created']}, "
                            f"reused={self._pool_stats['connections_reused']}, "
                            f"slow={self._pool_stats['slow_connections']}"
                        )
                        self._pool_stats['last_warning'] = now
                elif is_onboarding_context and connection_time < 0.5:
                    # Log fast onboarding connections for performance tracking
                    logger.debug(f"üëã FAST ONBOARDING: {context_id} connected in {connection_time:.3f}s")
                
                yield session
                session.commit()
                break  # Success, exit retry loop
                
            except Exception as e:
                error_msg = str(e)
                if session:
                    session.rollback()
                    
                # SSL FIX: Handle SSL connection errors with retry logic and monitoring
                if "SSL connection has been closed unexpectedly" in error_msg and retry_count < max_retries - 1:
                    retry_count += 1
                    # SSL MONITORING: Record SSL retry
                    record_ssl_retry(f"database_pool_session_{context_id}", retry_count, error_msg)
                    logger.debug(f"üîå SSL connection retry {retry_count}/{max_retries} for {context_id}: {error_msg}")
                    if session:
                        try:
                            session.close()
                        except Exception as e:
                            pass
                    # SSL FIX: Dispose engine to force fresh SSL connections on repeated errors
                    if retry_count > 1:
                        logger.warning(f"üîå Multiple SSL errors for {context_id} - disposing engine")
                        self.engine.dispose()
                    session = None
                    time.sleep(0.5 * retry_count)  # Exponential backoff
                    continue
                else:
                    # SSL MONITORING: Record SSL error for final failure
                    if "SSL connection has been closed unexpectedly" in error_msg:
                        record_ssl_error(f"database_pool_session_{context_id}", error_msg, retry_count + 1)
                    # Non-SSL error or max retries exceeded
                    if retry_count > 0:
                        logger.error(f"‚ùå SSL connection failed after {retry_count + 1} attempts for {context_id}: {error_msg}")
                    raise
            finally:
                if session and retry_count < max_retries:  # Only close if we're not retrying
                    # Return session to pool instead of closing
                    session.close()
                    
                    # MEMORY OPTIMIZATION: Maintain separate pools with proper minimums
                    general_min = 2
                    onboarding_min = 1 if is_onboarding_context else 0
                    
                    # Refill general pool
                    if len(self._warmed_sessions) < general_min:
                        threading.Thread(
                            target=lambda: self._warm_connections(1),
                            daemon=True
                        ).start()
                    
                    # Refill onboarding pool if needed
                    if is_onboarding_context and len(self._onboarding_warmed_sessions) < onboarding_min:
                        threading.Thread(
                            target=lambda: self._warm_onboarding_connections_dedicated(),
                            daemon=True
                        ).start()
                        logger.debug("üëã ONBOARDING: Auto-warming dedicated onboarding session")
    
    def get_pool_statistics(self) -> Dict[str, Any]:
        """Get current pool performance statistics"""
        avg_connection_time = (
            sum(self._connection_times) / len(self._connection_times)
            if self._connection_times else 0
        )
        
        return {
            'avg_connection_time': avg_connection_time,
            'connections_created': self._pool_stats['connections_created'],
            'connections_reused': self._pool_stats['connections_reused'],
            'slow_connections': self._pool_stats['slow_connections'],
            'pool_size': self.engine.pool.size(),
            'pool_checked_out': self.engine.pool.checkedout(),
            'pool_overflow': self.engine.pool.overflow(),
            'warmed_sessions': len(self._warmed_sessions),
            'onboarding_warmed_sessions': len(self._onboarding_warmed_sessions)
        }
    
    async def maintain_pool_health(self):
        """Background task to maintain pool health - REDUCED FREQUENCY"""
        while True:
            try:
                # PERFORMANCE FIX: Check pool health every 5 minutes instead of 30 seconds
                # This reduces overhead significantly and prevents excessive warming cycles
                await asyncio.sleep(300)  # Changed from 30 to 300 seconds (5 minutes)
                
                stats = self.get_pool_statistics()
                
                # RELAXED: Only log if performance severely degrades (increased threshold)
                if stats['avg_connection_time'] > 2.0:  # Increased from 1.0s to 2.0s
                    logger.warning(f"üîß Pool performance degraded: {stats}")
                    
                # RELAXED: Only refresh if many more slow connections (increased threshold)
                if stats['slow_connections'] > 20:  # Increased from 10 to 20
                    logger.info("üîÑ Refreshing connection pool due to poor performance")
                    self.engine.dispose()  # Dispose of current pool
                    self._pool_stats['slow_connections'] = 0
                    self._warm_connections(2)  # REDUCED: Only warm 2 instead of 3 connections
                    
            except Exception as e:
                logger.error(f"Pool maintenance error: {e}")
                await asyncio.sleep(60)


# Singleton instance - initialize fresh to clear any cached configuration
database_pool = OptimizedDatabasePool()


def get_optimized_session(context_id: str = "default"):
    """Get an optimized database session"""
    return database_pool.get_session(context_id)


def get_webhook_hardened_session(context_id: str = "webhook"):
    """Get a database session with hardened timeouts for webhook processing"""
    # Temporarily enable webhook context for this session
    original_context = getattr(database_pool, '_webhook_context', False)
    database_pool.set_webhook_context(True)
    try:
        return database_pool.get_session(context_id)
    finally:
        database_pool.set_webhook_context(original_context)


def get_onboarding_optimized_session(context_id: str = "onboarding"):
    """Get a database session optimized for fast onboarding flows
    
    This provides priority access to pre-warmed connections and enhanced
    monitoring specifically tuned for user registration performance.
    """
    # Temporarily enable onboarding context for this session
    original_context = getattr(database_pool, '_onboarding_context', False)
    database_pool.set_onboarding_context(True)
    try:
        return database_pool.get_session(context_id)
    finally:
        database_pool.set_onboarding_context(original_context)


# Export for backward compatibility
SessionLocal = database_pool.SessionFactory